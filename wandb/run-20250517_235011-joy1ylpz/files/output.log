Input dimension changed from 64 to 21 due to positional encoding.
encoder_dims: [64, 32, 16, 8], decoder_dims: [8, 16, 32, 64]
Epoch 1: 0it [00:00, ?it/s]/home/amarjay/Desktop/code/neural_audio_modulation/neural_audio_modulation/src/training/train.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).


orig_shape: torch.Size([8, 1, 220500, 1]), out shape: 21, embedded shape: torch.Size([1764000, 21])
embedded shape after reshape: torch.Size([8, 1, 220500, 21])
  audio_input = torch.tensor(batch[0], device=device)


orig_shape: torch.Size([8, 1, 220500, 1]), out shape: 21, embedded shape: torch.Size([1764000, 21])
embedded shape after reshape: torch.Size([8, 1, 220500, 21])
Epoch 1: 0it [00:00, ?it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/amarjay/Desktop/code/neural_audio_modulation/neural_audio_modulation/src/training/train.py", line 105, in <module>
    train_model(config)
  File "/home/amarjay/Desktop/code/neural_audio_modulation/neural_audio_modulation/src/training/train.py", line 83, in train_model
    evaluate_model(model.encoded, model.decoded, train_loader, cross_entropy_loss=loss)
  File "/home/amarjay/Desktop/code/neural_audio_modulation/neural_audio_modulation/src/training/train.py", line 92, in evaluate_model
    encoded = encoder(audio_input)
  File "/home/amarjay/Desktop/code/neural_audio_modulation/neural_audio_modulation/src/models/model.py", line 177, in encoded
    x = layer(x)
  File "/home/amarjay/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/amarjay/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/amarjay/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1764000x21 and 64x32)
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/amarjay/Desktop/code/neural_audio_modulation/neural_audio_modulation/src/training/train.py", line 105, in <module>
    train_model(config)
  File "/home/amarjay/Desktop/code/neural_audio_modulation/neural_audio_modulation/src/training/train.py", line 83, in train_model
    evaluate_model(model.encoded, model.decoded, train_loader, cross_entropy_loss=loss)
  File "/home/amarjay/Desktop/code/neural_audio_modulation/neural_audio_modulation/src/training/train.py", line 92, in evaluate_model
    encoded = encoder(audio_input)
  File "/home/amarjay/Desktop/code/neural_audio_modulation/neural_audio_modulation/src/models/model.py", line 177, in encoded
    x = layer(x)
  File "/home/amarjay/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/amarjay/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/amarjay/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1764000x21 and 64x32)
